% !TeX spellcheck = en_US
\documentclass[11pt, fleqn, titlepage]{article}
%\usepackage{siunitx}
\usepackage{texfiles/SpeedyGonzales}
\usepackage{texfiles/MediocreMike}
\newcommand{\so}[2]{{#1}\mathrm{e}{#2}}
% \geometry{top=1cm}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{booktabs}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=cyan,
}
\usepackage{subfig}
\usepackage{graphicx}
\title{Human arm trajectories in obstacle avoidance}
\author{Oskar Eiler Wiese Christensen s183917 \\ Anders Henriksen s183904 \\ \\ 02445 Project in Statistical Evaluation of Artificial Evaluation}
\date{\today \vspace{2.5cm} \section*{Abstract} \textit{The summary should contain a summary of the problem that  you are working with, which results you got, as well as main conclusions. \\ Don’t get into technical details. The summary should not be very long} \\ In this paper, the goal is, using the \texttt{armdata.Rdata} dataset, to determine if people can be recognized based on their movements, and if obstacles change the movement curve of the hand of the subject in question.
\\ Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida arcu ac tortor dignissim. Et netus et malesuada fames. Convallis posuere morbi leo urna molestie at elementum eu facilisis. Etiam erat velit scelerisque in dictum non. Mollis nunc sed id semper risus in hendrerit gravida. Cursus euismod quis viverra nibh cras pulvinar mattis nunc sed. Eu tincidunt tortor aliquam nulla. Duis convallis convallis tellus id interdum. Nunc lobortis mattis aliquam faucibus purus in massa tempor. Feugiat sed lectus vestibulum mattis ullamcorper. Malesuada proin libero nunc consequat interdum varius. Sed pulvinar proin gravida hendrerit lectus. Varius morbi enim nunc faucibus a. Ultricies leo integer malesuada nunc vel risus commodo viverra maecenas. Id aliquet lectus proin nibh nisl. Ullamcorper velit sed ullamcorper morbi tincidunt.}

\pagestyle{plain}
\fancyhf{}
\rfoot{Page \thepage{} of \pageref{LastPage}}

\graphicspath{{Billeder/}}

\begin{document}

\maketitle
%\thispagestyle{fancy}
%\tableofcontents

\section{Introduction}
\textit{Briefly introduce the background and setting of the problem, as well as the aim of the report. Furthermore, you could give a very short description of the analysis that will be applied.} \\ \\
Security plays a larger role in existence every year, whether used for personal security or for the governmental spying on billions. Throughout the years, sercurity has taken many forms like facial and voice recognition, but movement recognition, if it proves successful, could turn out to be an effective way of finding perpetrators of crimes or locking people into their own homes. For this to truly be effective, it should be possible to classify people based on their movements and maybe even recognize actions based on the motion curve.

This is exactly what is wished to be accomplished in this paper; Classify the person performing the action based on the given motion curve using decision trees and K-nearest neighbors, and analyzing whether the type of obstacle has an influence on the resulting curve by the use of t-tests and ANOVA. For this, the focus has been specifically on the arm movement dataset from \textbf{Grimme et al. 2014}. The hypothesis prior to the carrying out of the experiment was that it should be possible to classify the person based on the curve, since people can move in substantially different ways. It is also expected that experiment should play a significant role on the resulting curve, since a much taller obstacle should make people lift their arms much more dracstially.

\section{Data}
\textit{Describe of the data you are analyzing. What kinds of data do you have, how were they collected (if applicable)? \\ Include a few good plots to highlight important features in data. You can put additional plots in the appendix.}
\\\\
%*\textbf{Description of data:}
Ten different test subjects performed obstacle avoidance tasks on a table by relocation of a cylindrical object from position A to position B. Different experiments, with varying heights of the obstacle were executed, and the test subjects were furthermore asked to avoid the obstacle by lifting the cylindrical object at hand. The movements were recorded with VZ 4000. The trajectories of markers were recorded using a sampling rate of 110 Hz. The starting position projected to the table is considered the origin in a three dimensional space. Fifteen different obstacle avoidance experiments were conducted, with one experiment for every S,M, or T with the given measure $ d \in \{15, 22.5,  30, 37.5, 45\} $ as well as a control experiment with no obstacle. Each person repeated each of the sixteen different experiments ten times. The full data have a total size of $ m_f = 174,160 $. \cite{armdata}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{billeder/exp_pic.png}
	\caption{An illustration of the obstacle avoidance setup. Test subjects have to move the cylinder from start to the finnish position "target", while avoiding the blue obstacle.}
	\label{fig:exppic}
\end{figure}
The data itself consists of recorded trajectory movements, by measured $ x,y,z $-coordinates in a three dimensional space. An illustration of the coordinates are given in \ref{fig:rplot}. Here the variables S, M and T vary in the different experiments. An example of ten different arm-trajectory paths of a test subject repeating the same experiment is shown in the figure \ref{fig:rplot}.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{billeder/Rplot.png}
	\caption{An illustration of test subject 1's arm trajectories in experiment 1 repetition one through ten}
	\label{fig:rplot}
\end{figure}

%%TODO: forklare lidt om ovenstående. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{billeder/boxplot_z.pdf}
	\caption{Boxplots of the variation in the Z-dimension of the arm trajectories for all test subjects}
	\label{fig:boxplotz}
\end{figure}

Figure \ref{fig:boxplotz} shows a notable variation in the Z-dimension which indicates that it may be possible to distinguish each test subjects trajectory arm movements. In \ref{fig:boxplotz}, the variation is greater for $ z \in [13,85] $ than in the tails, which makes sense since each subject moves the cylindrical object from the same start position to the same end position.
\\\\
A principle component analysis is done in order to investigate the dimensionality and variation of the data. The analysis yields a hundred principle components, whereas a lot of the variation is explained by the first couples as illustrated below, 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{billeder/varexp.png}
	\caption{}
	\label{fig:varexp}
\end{figure}

In order to explain 90 \% of the variation of the data, the first eight principle components are needed, which also can be noted from figure \ref{fig:varexp}. By having a great proportion of the variance explained by relatively few principle components it seems possible to construct a classifier in order to determine a person from his/her trajectory paths.
\\
To get a visual grasp of the original data points projected onto the space of the principle components, a scatter plot of the transformed data in the principle component space is plotted as seen below,

\begin{figure}[H]
	\centering
	\subfloat[label 1]{{\includegraphics[width=5cm]{billeder/pca1.pdf} }}%
	\qquad
	\subfloat[label 2]{{\includegraphics[width=5cm]{billeder/pca2.pdf} }}%
	\caption{Left: A plot of the first two principle components of the data. Right: A plot of the third and fourth principle component. The numbers from 1 to 100 illustrate the date projected onto the principle components}%
	\label{fig:example}%
\end{figure}


\section{Methods}
\textit{Describe the methods you used and why you decided to use them. Also discuss the assumptions behind the methods. Do not go into detail with theory.}

\subsection*{Models}
Two different models are constructed in order to classify a specific test subject based on the resulting curve of the arm trajectories. 

\subsubsection*{Binary Classification Tree}
One of the machine learning models used for classification is a binary classification tree. A classification tree is constructed by splitting data into subsets. In the case of a binary classification tree each branch is split into two subsets. The splitting is based Hunts algorithm, and the best split is the one with highest purity gain. The splitting ends when the splits no longer adds value to the predictions. 

\subsubsection*{K-nearest neighbors}
The second machine learning model used for classification is a K-nearest neighbor classifier. The model is constructed by storing the all of data. When the model predicts it chooses the K-nearest neighbors with euclidean distance as the measure. The model implemented uses majority voting and if there is a tie between the neighbors the closest neighbor is chosen as the prediction. As for this experiment the classifier uses $ K=3 $ based on pilot experiments.

\subsection*{Comparison of models}
To statistically compare the models a McNemar test is chosen. The models are compared under the following hypothesis. 

\begin{align*}\label{key}
H_0 : & \hat \theta_1 =  \hat \theta_2 \\
H_1 : & \hat \theta_1 \neq  \hat \theta_2
\end{align*}
Where $ \hat \theta_1 $ and $ \hat \theta_2  $ is the estimated accuracy of models. The \textbf{n} matrix is calculated as, 
\begin{equation*}\label{key}
\begin{aligned}
n_{11} &=\sum_{i=1}^{n} c_{i}^{A} c_{i}^{B} \qquad= \{ \text{Both classifiers are correct} \} \\
n_{12} &=\sum_{k=1}^{n} c_{i}^{A}\left(1-c_{i}^{B}\right) \quad=\{A \text { is correct, } B \text { is wrong }\} \\
n_{21} &=\sum_{k=1}^{n}\left(1-c_{i}^{A}\right) c_{i}^{B} \quad=\{A \text { is wrong, } B \text { is correct }\} \\
n_{22} &=\sum_{k=1}^{n}\left(1-c_{i}^{A}\right)\left(1-c_{i}^{B}\right)=\{\text { Both classifiers are wrong }\}
\end{aligned}
\end{equation*}
\noindent
The p-value is then calculated using the following expression, 
\begin{equation}\label{key}
p=2 \mathrm{cdf}_{\mathrm{binom}}\left(m=\min \left\{n_{12}, n_{21}\right\} | prop=\frac{1}{2}, N=n_{12}+n_{21}\right)
\end{equation}
\noindent
The interpretation is that the lower p is, the more evidence there is A is better than B,
but this is only to be interpreted along with the confidence interval given by the following expression.

\begin{equation}\label{key}
\begin{aligned}
&\theta_{L}=2 \operatorname{cdf}_{B}^{-1}\left(\frac{\alpha}{2} | \alpha=p, \beta=q\right)-1\\
&\theta_{U}=2 \operatorname{cdf}_{B}^{-1}\left(1-\frac{\alpha}{2} | \alpha=p, \beta=q\right)-1
\end{aligned}
\end{equation}
\noindent
If zero is not observed in the interval given by, $ [\theta_{L},\theta_{U}] $ and the p-value is significant, then model A is better than model B \cite{mlbog}.

\subsection*{Test-statistics}
To test whether there is a significant effect of experiment on the resulting curve a analysis of variance is used as statistical test. 

\subsubsection*{Analysis of Variance: ANOVA}
ANOVA is used when all the explanatory variables are factors. In the case of this experiment there are four explanatory variables these are the person, repetition, experiment and whether its a x,y or z coordinate. The response variable is the position, i.e. the resulting curve. Thus, a four-way Anova is conducted on the data. The null hypothesis is that all the resulting curves in each experiment comes from the same population and therefore there is no difference in the means og the resulting curves. The reason why an Anova test is chosen rather than a t-test is due to the fact that Anova minimizes the type I error. \cite{statbog}


\section{Results}
\textit{Present the results. \\ Tables and figures are good ways of illustrating results.} \\
Using the 3-nearest neighbor and binary classification tree models to classify the person from the curve yielded the following results.

\begin{table}[h]
	\centering
	\begin{tabular}{l r}
		\toprule
		Classification Model       & Accuracy  \\ \midrule
		3-Nearest neighbor         & 0.62      \\ 
		Binary classification tree & 0.47      \\ \bottomrule
	\end{tabular}
\end{table}

\noindent To test if this difference between accuracies is significant, and if the models are significantly different, McNemar's test has been performed. The result of this test is shown below.

\[n = \begin{bmatrix} n_{11} & n_{12} \\ n_{21} & n_{22} \end{bmatrix} = \begin{bmatrix} \text{Both classifiers are correct} & \text{One classifier is correct} \\ \text{The other classifier is correct} & \text{Both classifiers are wrong} \end{bmatrix} = \begin{bmatrix} 37 & 25 \\ 10 & 28 \end{bmatrix}\] 

\begin{table}[H]
	\centering
	\begin{tabular}{l r}
		\toprule
		Measure        & Value                          \\ \midrule
		$\hat{\theta}$ & 0.15                           \\ 
		p-value        & 0.0167                         \\ 
		CI             & $0.0375 \leq 0.150 \leq 0.261$ \\ \bottomrule
	\end{tabular}
\end{table}

\noindent Using ANOVA, the following results have been gathered for investigating whether the experiment has a significant effect on the resulting curve.

\begin{table}[H]
	\centering
	\begin{tabular}{l r}
		\toprule
		Variable       & p-value                         \\ \midrule
		Position       & $<2.200 \cdot 10^{-16}$         \\ 
		Repetition     & $5.424 \cdot 10^{-7}$           \\ 
		Person         & $<2.200 \cdot 10^{-16}$         \\ 
		Experiment     & $<2.200 \cdot 10^{-16}$         \\ \bottomrule
	\end{tabular}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{billeder/PredHist.png}
	\caption{}
	\label{fig:predhist}
\end{figure}

\section{Discussion}
\textit{What do your results show? \\ Discuss your results. How reliable are they?}

\section{Conclusion}
\textit{What are your conclusions? The conclusion should be connected to the aim of the report in the introduction. \\ Highlight important results \\ If you have found interesting problems/aspects that you haven’t carried out, you can specify them here as ‘future work’.}

\section{Appendix}


\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}
